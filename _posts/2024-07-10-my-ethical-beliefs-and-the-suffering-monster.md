---
title: "My ethical beliefs and the suffering monster"
date:   2024-07-10 10:00:00 +0530
subheadline: ""
category: non-physics
tags:   [Ethics,Important]
image:
    thumb: 2024-07-10-thumb1.png
script:
  foot: bookmarklet.js
---
People are not obliged to be intelligent or creative or rich or influential or attractive or muscular or tall or to do only legal things etc. But there is one thing that people are obliged to and it is being ethical. So, everyone has an obligation to think about ethics and choose a consistent ethical theory that they think is the best. In this post, I will explain why I believe in an ethical theory called "Threshold Deontology". Towards the end, I will give a reductio ad absurdum argument called the "suffering monster" (inspired by "<a href="https://en.wikipedia.org/wiki/Utility_monster" target="_blank">utility monster</a>" but slightly different due to the asymmetry between pleasure and suffering) that explains why the theory I believe in is incomplete. But this theory is enough for practical purposes. In the end, I speculatively argue for the existence of an objective and mathematically rigorous theory called "ethics M-theory".<!--more-->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
    
<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

- [My ethical beliefs](#my-ethical-beliefs)
   * [Negative utilitarianism](#negative-utilitarianism)
      + [Consistency](#consistency)
   * [Threshold deontology](#threshold-deontology)
      + [Proximity](#proximity)
- [The suffering monster](#the-suffering-monster)
- [Free will](#free-will)
- [Conclusion](#conclusion)
   * [Precise thresholds](#precise-thresholds)
   * [M-theory](#m-theory)

## My ethical beliefs

### Negative utilitarianism

As far back as I can remember, I was always a negative utilitarian (till 2021), even before I heard its name.

<a href="https://en.wikipedia.org/wiki/Utilitarianism" target="_blank">Classical utilitarianism</a> tells us to maximize utility. Utility can be increased by increasing the pleasure or decreasing the suffering; both are considered equally important.

<a href="https://en.wikipedia.org/wiki/Gautama_Buddha" target="_blank">Siddhārtha Gautama</a> (as an atheist, I do not call him “The Buddha”) explained that desires are the origin of suffering in his "<a href="https://en.wikipedia.org/wiki/Four_Noble_Truths" target="_blank">Four Noble Truths</a>". Because of this, since childhood, I always had a negative view of pleasures, especially sensual pleasures. Siddhārtha’s statement is an exaggeration because there is suffering that is not caused by desires[^Fear], like deaths due to tornadoes, etc. But, I still think his statement is an important contribution to philosophy and it strongly supports that reducing suffering is more important than increasing pleasure.

But, there is a more proper argument for this called <a href="https://en.wikipedia.org/wiki/Benatar%27s_asymmetry_argument" target="_blank">Benatar's asymmetry argument</a>[^Antinatalism].

| Presence                    | Absence                       |
|-----------------------------|-------------------------------|
| <span style="color:red">Presence of pain (Bad)</span>      | <span style="color:green">Absence of pain (Good)</span>        |
| <span style="color:green">Presence of pleasure (Good)</span> | Absence of pleasure (Not bad) |

As the above table explains, the presence of pain is a much bigger issue than the absence of pleasure. Popper was one of the first to realize this in 1945 and he then proposed negative utilitarianism. <a href="https://en.wikipedia.org/wiki/Shantideva" target="_blank">Śāntideva</a> was the first negative utilitarian, preceding Popper by a millennium. Although, as I said before, indirectly, it was already present in the philosophy of <a href="https://en.wikipedia.org/wiki/Gautama_Buddha" target="_blank">Siddhārtha Gautama</a>.

>“I believe that there is, from the ethical point of view, no symmetry between suffering and happiness, or between pain and pleasure. Both the greatest happiness principle of the Utilitarians and Kant's principle 'Promote other people's happiness ..' seem to me (at least in their formulations) wrong on this point which, however, is not completely decidable by rational argument. In my opinion human suffering makes a direct moral appeal, namely, the appeal for help, while there is no similar call to increase the happiness of a man who is doing well anyway. (A further criticism of the Utilitarian formula 'Maximize pleasure' is that it assumes, in principle, a continuous pleasure-pain scale which allows us to treat degrees of pain as negative degrees of pleasure. But, from the moral point of view, pain cannot be outweighed by pleasure, and especially not one man's pain by another man's pleasure. **Instead of the greatest happiness for the greatest number**, one should demand, more modestly, **the least amount of avoidable suffering for all**; and further, that unavoidable suffering—such as hunger in times of an unavoidable shortage of food—should be distributed as equally as possible.)”

― <a href="https://en.wikipedia.org/wiki/Karl_Popper" target="_blank">Karl Popper</a>

>“If a bodhisattva does not make a sincere, unwavering effort in thought, word, and deed **to stop all the present and future pain and suffering of all sentient beings, and to bring about all present and future pleasure and happiness**, or does not seek the collection of conditions for that, or does not strive to prevent what is opposed to that, or does not bring about small pain and suffering as a way of preventing great pain and suffering, or does not abandon a small benefit in order to accomplish a greater benefit, if he neglects to do these things even for a moment, he undergoes a downfall. (see SS-G: 17).”

― <a href="https://en.wikipedia.org/wiki/Shantideva" target="_blank">Śāntideva</a>

#### Consistency

In the original <a href="https://en.wikipedia.org/wiki/Trolley_problem" target="_blank">trolley problem</a>, like most people, I too once thought that we should kill 1 person to save 5 people. But then, when I read the below slight modification of the trolley problem, I thought 1 person should not be killed to save 5 people.

*<a href="https://www.jstor.org/stable/4320118" target="_blank">The Transplant problem</a>: A brilliant transplant surgeon has five patients, each in need of a different organ, each of whom will die without that organ. Unfortunately, there are no organs available to perform any of these five transplant operations. A healthy young traveler, just passing through the city the doctor works in, comes in for a routine checkup. In the course of doing the checkup, the doctor discovers that his organs are compatible with all five of his dying patients. Suppose further that if the young man were to disappear, no one would suspect the doctor.*

My intuition said that in the above problem, the healthy young traveler should not be murdered. So, I understood my beliefs were inconsistent. Most people also answered similarly to me. So, most people are also inconsistent in their ethics. Most people also think about <a href="https://en.wikipedia.org/wiki/Trolley_problem#The_Fat_Man" target="_blank">The Fat Man</a> problem as similar to The Transplant problem and different from the original problem.

<a href="https://en.wikipedia.org/wiki/Negative_utilitarianism#The_benevolent_world-exploder" target="_blank">The benevolent world-exploder</a> is another similar counterexample to Negative utilitarianism.

I think the reason most people have inconsistent ethics is because of the lack of ethics in school curriculums. As I mentioned at the beginning, ethics is something everyone must know, and physics or chemistry or maths is not something that everyone needs to know. So, every high school curriculum should teach ethics as a subject, just as they teach science and maths. There are many good books which can be used to teach ethics. One particularly good book that I can recommend is [Introduction to Ethics: Concepts, Theories, and Contemporary Issues By Chhanda Chakraborti](https://books.google.com/books?id=f5jXEAAAQBAJ&printsec=frontcover&newbks=0&hl=en&ovso=1#v=onepage&q&f=false). It is a very good book and can be divided into parts and can be taught over several years of high school. The only section where I know more than the author is section 5.3.5 Non-human Rights. In that section, she wrote some incorrect things. She says Peter Singer is an animal rights philosopher. But he is not. We can't blame her because Peter Singer is widely called "[the father of animal rights](https://www.abolitionistapproach.com/challenging-peter-singers-paternity-claim/){:target="_blank"}". But he is only a welfarist. Singer [proclaims](https://www.newstatesman.com/ideas/2021/05/peter-singer-why-case-veganism-stronger-ever){:target="_blank"} that meat-eating may be permissible if “farms really give the animals good lives, and then humanely kill them, preferably without transporting them to slaughterhouses or disturbing them. In Animal Liberation, I don’t really say that it’s the killing that makes [meat-eating] wrong, it’s the suffering.” This quote should make it clear; he is a welfarist based on negative utilitarianism.

The real people who started animal rights philosophy are Tom Regan and Gary L. Francione (both independently). For example, you can see [The Six Principles of the Abolitionist Approach to Animal Rights](https://www.abolitionistapproach.com/about/the-six-principles-of-the-abolitionist-approach-to-animal-rights/){:target="_blank"}. As Tom Regan explains in the below quote, because of his [1983 book](https://en.wikipedia.org/wiki/The_Case_for_Animal_Rights){:target="_blank"}, there was more philosophical research about animal rights in the next 20 years than all of previous human history combined.

>“Philosophers have written more about animal rights in the past twenty years than their predecessors wrote in the previous two thousand. Not surprisingly, disagreements abound. To begin with, among those who challenge attributing moral rights to animals are philosophers who operate within well-worn moral traditions in Western thought. Peter Singer (1975, 1999) and Carl Cohen (1986, 1996, 1997) are representative. Singer follows in the tradition of the nineteenth-century English utilitarian Jeremy Bentham, who ridicules moral rights as “nonsense upon stilts.” For both Bentham and Singer, not only nonhuman animals but also humans lack moral rights. This is half-true, maintains Cohen. Animals, he argues, most certainly do not have moral rights, but Bentham and Singer err when they deny that humans have them. Nothing could be further from the truth. According to Cohen, not just some but all humans possess basic rights, including the rights to life and to bodily integrity.” [ Regan (2001), p. 67.]

― <a href="https://en.wikipedia.org/wiki/Tom_Regan" target="_blank">Tom Regan</a>

### Threshold deontology

Once I understood that I was not consistently a negative utilitarian, I had to find a better ethical theory to believe in. I thought about believing in rights, but only approximately. I think in the 1 vs 5 trolley problem, we should not kill 1 person to save 5 people because we should respect the right of that one person. But if we change the number $5$ to $N\to \infty$ (some large number like billion or trillion), then I think it is ok to kill one person to save that many people. So, I thought from the beginning that rights are only approximate. So, in the "large N" approximation, we should use negative utilitarianism instead of rights theory. But what is the exact critical value of $N$ at which this transition happens? I don't know! What I am considering here is called <a href="https://en.wikipedia.org/wiki/Negative_utilitarianism#Combining_negative_utilitarianism_with_rights" target="_blank">Combining negative utilitarianism with rights (CNUWR)</a>.

But in CNUWR, you can ask where these rights come from. Certainly, they can't be arbitrary. One way to explain these rights is in the style of <a href="https://en.wikipedia.org/wiki/Rule_utilitarianism" target="_blank">rule utilitarianism</a> (until now, I have only talked about <a href="https://en.wikipedia.org/wiki/Act_utilitarianism" target="_blank">act utilitarianism</a>). We can adopt those rights, which reduce a lot of suffering. For example, the [right not to be treated as the property of all sentient beings](https://www.abolitionistapproach.com/about/the-six-principles-of-the-abolitionist-approach-to-animal-rights/){:target="_blank"}.

But, there is another slightly better and very similar theory called <a href="https://doi.org/10.1017/9781108227025.022" target="_blank">Threshold Deontology</a>. One main difference between them is that in CNUWR, the rights are absolute. Rights are constraints in CNUWR, and we have to reduce suffering without violating these constraints. CNUWR, like any absolute deontological theories, has a big problem. Staunch deontologists like Kant would never do anything they consider bad, even if it means the entire world will perish. I think such a view is ridiculously stupid.

>“Better the whole people perish than that injustice be done.”

― <a href="https://en.wikipedia.org/wiki/Immanuel_Kant" target="_blank">Immanuel Kant</a>

Threshold Deontology solves this problem. You can have a [maxim](https://en.wikipedia.org/wiki/Maxim_(philosophy)){:target="_blank"} like "Do not lie". You can't lie for trivial things like pranks or to earn a little money, etc., according to it. But things are permitted after a threshold, like a lie that can save a sentient being's life. Of course, there should be different thresholds for violating different maxims. For example, saving a single sentient being is enough of a threshold to lie. But saving a single sentient being is not enough threshold to murder another sentient being. But if you can save a billion sentient beings by killing a single sentient being, then that murder is morally justifiable even though you are violating the right of a sentient being. Determining exact thresholds is a problem that I will talk [at the end](#precise-thresholds). ***<span style="color:green">If you are not violating any maxims, then the goal is always to reduce suffering. But you have to respect the maxims before the thresholds.</span>***


After the thresholds, I will follow negative utilitarianism. But before that, what kind of deontology should I follow? One option is to following [Kantian ethics](https://en.wikipedia.org/wiki/Kantian_ethics){:target="_blank"}, which is based on his [Categorical Imperative](https://en.wikipedia.org/wiki/Categorical_imperative){:target="_blank"}. One nice thing about the  Categorical Imperative is that all immoral actions are irrational because they violate the CI. This is something I think is intuitively true. A perfectly rational being will never do anything immoral.

Tom Regan also follows Kantian ethics. But another option to define maxims is, as mentioned before, in the style of <a href="https://en.wikipedia.org/wiki/Rule_utilitarianism" target="_blank">rule utilitarianism</a>. I think there is not much practical difference in how we define these maxims. So, I don't have a preference.

#### Proximity

Peter Singer long ago made a famous argument called the <a href="https://www.philosophyexperiments.com/singer/" target="_blank">The Drowning Child</a>. The conclusion was that morality should not depend on proximity, whether it is spatial proximity or emotional proximity. If you can save 1 person in the USA who is right next to you, but with the same money, you can save 10 people in Africa who are not right next to you, then you should not care about spatial proximity. Similarly, humans have emotional proximity to dogs and cats but don't have for pigs or chickens, but that is irrelevant to morality.

If the above is the claim, that is something I completely agree with. But very often, this claim is promoted as part of utilitarianism, which I dislike. Recently, this argument was rebranded into a movement called <a href="https://en.wikipedia.org/wiki/Effective_altruism" target="_blank">Effective Altruism</a>. Some people in this movement even believe absurd things like they can consume animal products daily if they donate a million dollars to save many animals because they would have saved more lives than they will ever eat in their lives. This is a reductio ad absurdum of utilitarianism. Imagine if someone kills 10 people near him and then saves 1000 people who would have died due to starvation. Does saving 1000 people justify killing 10 people? Of course not. ***That's basically like saying morality doesn't apply to rich people.***

In Threshold Deontology, the logic used by Effective Altruism only works when we go beyond the thresholds and enter the realm of utilitarianism. We must do our deontological obligations, like not killing people. When we consider things we are not responsible for (like wild animal suffering, world hunger, etc.), then we should think in terms of Effective Altruism.

## The suffering monster

In 2022, just after I started believing in threshold deontology, I read Robert Nozick's[^Nozick] <a href="https://en.wikipedia.org/wiki/Utility_monster" target="_blank">utility monster</a>. I understood that if I slightly change his argument, that can be a counter-example to threshold deontology.

**The suffering monster argument**: Imagine a monster that has $\infty$ jealousy. Every time it sees a sentient being living its life, it will suffer $\infty$ because it is not the only sentient being existing. Assuming the threasolds of threshold deontology are finite, this would mean that we need to consider negative utilitarianism as the suffering is $\infty$. If such an organism ever sees me, will it become my moral obligation to kill my self?

Intuitively, it should be clear that it is not my moral obligation. So, threshold deontology is an incomplete theory.

## Free will

I believe in [Hard Incompatibilism](https://en.wikipedia.org/wiki/Incompatibilism#Hard_incompatibilism){:target="_blank"}, which says that free will is impossible irrespective of whether the fundamental laws of physics are deterministic or stochastic, which depends on the interpretation of quantum mechanics. I think we are all slaves to the laws of physics with no freedom. But like everyone, I, too, have a stubbornly persistent illusion that I have free will. The [hard problem of consciousness](https://en.wikipedia.org/wiki/Hard_problem_of_consciousness){:target="_blank"} is why we have this illusion, and I am not interested in that question. While I strongly believe that free will is an illusion, I am agnostic towards [Illusionism (consciousness)](https://en.wikipedia.org/wiki/Eliminative_materialism#Illusionism){:target="_blank"} as I don't know enough about consciousness. Many things, like classical spacetime, water, etc, are approximate emergent notions that "exist" at some scales but do not really exist fundamentally. Consciousness "exists" similarly as an emergent phenomenon. But free will can't exist as long as the fundamental laws of physics are either deterministic or stochastic with a precise probability distribution.

It might seem that the lack of free will implies [moral responsibility is impossible](https://plato.stanford.edu/entries/skepticism-moral-responsibility/){:target="_blank"}. But I think moral responsibility does exist because, due to the Categorical Imperative, you have to be moral to be a rational person, and just like you MUST NOT "willfully" believe misinformation, you MUST NOT "willfully" do immoral things as a rational being. Doing immoral things is irrational. It is the fundamental duty of sapient beings (i.e., beings capable of abstract thought, homo sapiens are the only sapient species until we discover intelligent aliens) to be rational and not to "willfully" do irrational things. Here, "willfully" is an approximate notion consistent with the illusion of free will. Of course, nothing is really willful because free will doesn't exist. An anti-vaxxer might seem like a willfully ignorant person, but what can he do if the laws of physics dictated him to be stupid? But we shouldn't give up and believe in nonsense just because we don't have free will; we can, for example, prove mathematical truths using [Lean](https://en.wikipedia.org/wiki/Lean_(proof_assistant)){:target="_blank"}, which doesn't depend on free will. Check [Is Free Will Scepticism Self-Defeating?](https://philpapers.org/rec/CHEIFW){:target="_blank"} on how being rational is consistent with the lack of free will.

[Retributive justice](https://en.wikipedia.org/wiki/Retributive_justice){:target="_blank"} is unjustifiable due to the lack of free will. But, deterrence, exile, and rehabilitation are acceptable forms of justice.

All sentient beings should be included in our moral consideration. But sentient beings that are not sapient, which includes every non-human animal, do not have moral responsibility. While it is evil that predators kill and eat herbivores, it is a natural evil like tsunamis, and can't be attributed to predators. But in the long term, when humanity is advanced enough, we have a moral duty to [Herbivorize Predators](https://www.herbivorizepredators.org/){:target="_blank"} without violating the rights of predators. The fact that humans and most animals (except <a href="https://en.wikipedia.org/wiki/Sponge" target="_blank">sponges</a>, <a href="https://en.wikipedia.org/wiki/Coral" target="_blank">corals</a>, etc) are sentient is true. The fact that no being has free will and it is an illusion is also true. But consciousness is more subtle, and I am not sure if it is an illusion.

## Conclusion

Even though the suffering monster is a counter-example, of course, you don't see things like utility monsters, suffering monsters, etc, in your daily life. So, for most practical purposes, it is a good theory. We next discuss a much bigger problem to threshold deontology.

### Precise thresholds

How do we define precise thresholds?

The fact that thresholds must exist within deontological theories and these are not *ad hoc* was argued in <a href="https://doi.org/10.1017/9781108227025.022" target="_blank">The Rationality of Threshold Deontology</a> by Michael S. Moore. But, we have no proper rational method to find these thresholds.

The trolley problem is actually a very simple looking problem as we only have two options (we can either pull the lever or do nothing) and one parameter (the ratio of the number of people on one track to the other). But even in the simplest example, I couldn't provide the precise threshold or critical value after which we should follow negative utilitarianism. This reminds me of the question of how many atoms are required to define the temperature of a system. Of course, one could say $\infty$ because, strictly speaking, thermodyamics assumes the <a href="https://en.wikipedia.org/wiki/Thermodynamic_limit" target="_blank">thermodynamic limit</a>. But thermodynamics works well even if we have a finite number of particles like an Avogadro constant number of particles. But it doesn't work if our system has just 1 particle. In this case, we don't have a precise threshold. Maybe similarly, in the case of the trolley problem, we don't have a precise threshold. Maybe threshold deontology is an approximation of a continuous theory, which starts with deontology and ends with negative utilitarianism, but instead of abrupt thresholds, there is a ***continuous*** theory in between. I will next talk about this Mythical theory that completes these 2 theories.

### M-theory

I believe in <a href="https://en.wikipedia.org/wiki/Moral_realism" target="_blank">moral realism (objective morality)</a>. So, I think there is a unique objective ethical theory. As argued in the previous section, it is a continuous, mathematically rigorous theory. Let's call it M(oral) theory or just **M-theory** in short. Like we only know the <a href="https://en.wikipedia.org/wiki/M-theory" target="_blank">physics M-theory</a> in the weak coupling limit, we know the ethics M-theory only in certain limits. In one limit, it becomes deontology and in another, it becomes negative utilitarianism, but instead of abrupt thresholds, there is a ***continuous*** theory in between that connects these 2 limits.

As mentioned before, the trolley problem is a very simple problem as we only have two options and one parameter. We can, of course, think about more complicated problems where we have many options that depend on many parameters. In these general cases, it will be very hard to know what the ethics M-theory says us to do. In science, we are lucky we have a very useful method, the <a href="https://en.wikipedia.org/wiki/Scientific_method" target="_blank">scientific method</a>, even though we don't really know why this method works so well (See: <a href="https://en.wikipedia.org/wiki/Problem_of_induction" target="_blank">Problem of induction</a>). Even then, we still haven't defined the physics M-theory. In ethics, we don't even have any method like the scientific method. So, the ethics M-theory will probably be understood long after the physics theory.

I want to reiterate again that despite all this, threshold deontology is more than enough for daily situations.

[^Fear]: But a modification that I think is true is: Desires are the root cause of fear. 

[^Antinatalism]:
    Benatar used this argument in the context of <a href="https://en.wikipedia.org/wiki/Antinatalism" target="_blank">antinatalism</a>. I can never accept antinatalism because I can't accept that my birth is immoral for reasons similar to the <a href="https://en.wikipedia.org/wiki/Self-Respect_Movement" target="_blank">Self-Respect Movement</a>. I have always found that antinatalism is a very logical argument and failed to find a mistake. But in 2022, when I read Nozick's <a href="https://en.wikipedia.org/wiki/Experience_machine" target="_blank">experience machine</a> I was happy because I think it solves the issue of antinatalism. He used it to argue against utilitarianism. But the argument tries to explain that there is something inherently positive about existing in reality. And that can also be used to argue against antinatalism. Nagel also thinks that experiencing reality is inherently positive.

    >“All of us, I believe, are fortunate to have been born.”

    >“There are elements which, if added to one's experience, make life better; there are other elements which if added to one's experience, make life worse. But what remains when these are set aside is not merely neutral: it is emphatically positive. ... The additional positive weight is supplied by experience itself, rather than by any of its consequences.”

    ― <a href="https://en.wikipedia.org/wiki/Thomas_Nagel" target="_blank">Thomas Nagel</a>

    I dislike both natalism and antinatalism; I am neutral on this issue. I think procreation is amoral.

[^Nozick]: Random fact: Robert Nozick died on the exact day I was born, 2002-01-23. I think he was a very good philosopher, but unfortunately, he was a speciesist.